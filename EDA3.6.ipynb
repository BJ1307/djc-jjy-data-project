{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math\n",
    "import matplotlib\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "mlr_data = pd.read_csv('/Users/jjy/Desktop/MLR Data/mlr_data.csv')\n",
    "mlr_data = shuffle(mlr_data,random_state=1)\n",
    "# Display the first few rows to understand the structure\n",
    "print(mlr_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Assuming the data has columns for treatments and cytokines, replace these column names with actual ones\n",
    "treatment1_col = 'concentration_1'\n",
    "treatment2_col = 'concentration_2'\n",
    "\n",
    "for treatment_col in [treatment1_col, treatment2_col]:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Histogram plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(mlr_data[treatment_col], kde=False, bins=20)\n",
    "    plt.title(f'Histogram of {treatment_col}')\n",
    "    plt.xlabel(treatment_col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Density plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.kdeplot(mlr_data[treatment_col], shade=True)\n",
    "    plt.title(f'Density Plot of {treatment_col}')\n",
    "    plt.xlabel(treatment_col)\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Loop through each unique analyte and plot, skipping if insufficient data\n",
    "unique_analytes = mlr_data['analyte'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Part of this code is adapted from https://matplotlib.org/stable/plot_types/basic/scatter_plot.html#sphx-glr-plot-types-basic-scatter-plot-py\n",
    "\"\"\"\n",
    "\n",
    "def plot_1d(treatment, analyte):\n",
    "    # data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment) &\n",
    "    #                     (mlr_data[\"concentration_2\"]==0) &\n",
    "    #                     (mlr_data[\"analyte\"]==analyte) &\n",
    "    #                     (mlr_data[\"donor_1_id\"]==\"LS 24 18861 58355\") &\n",
    "    #                     (mlr_data[\"donor_2_id\"]==\"LS 11 71012 CC00481\")\n",
    "    #                     ]\n",
    "    # data_2 = mlr_data.loc[ ((mlr_data[\"treatment_2\"]==treatment) &\n",
    "    #                     (mlr_data[\"concentration_1\"]==0)) & \n",
    "    #                     (mlr_data[\"analyte\"]==analyte) &\n",
    "    #                     (mlr_data[\"donor_1_id\"]==\"LS 24 18861 58355\") &\n",
    "    #                     (mlr_data[\"donor_2_id\"]==\"LS 11 71012 CC00481\")\n",
    "    #                     ]\n",
    "    data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment) &\n",
    "                        (mlr_data[\"concentration_2\"]==0) &\n",
    "                        (mlr_data[\"analyte\"]==analyte)\n",
    "                        ]\n",
    "    data_2 = mlr_data.loc[ ((mlr_data[\"treatment_2\"]==treatment) &\n",
    "                        (mlr_data[\"concentration_1\"]==0)) & \n",
    "                        (mlr_data[\"analyte\"]==analyte)\n",
    "                        ]\n",
    "    if data_1.empty & data_2.empty:\n",
    "        return\n",
    "    \n",
    "    X_2 = pd.DataFrame(data_2.copy()[\"concentration_2\"]).rename(columns={\"concentration_2\":\"concentration\"})\n",
    "    y_2 = pd.DataFrame(data_2.copy()[\"analyte_value\"])\n",
    "    X_1 = pd.DataFrame(data_1.copy()[\"concentration_1\"]).rename(columns={\"concentration_1\":\"concentration\"})\n",
    "    y_1 = pd.DataFrame(data_1.copy()[\"analyte_value\"])\n",
    "    X = pd.concat([X_1,X_2])\n",
    "    y = pd.concat([y_1,y_2])\n",
    "    corr = np.corrcoef(X.transpose().values,y.transpose().values)[0][1]\n",
    "    if  (abs(corr) < 0.5) | (X.size <= 5 ):\n",
    "        return\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(X, y)\n",
    "    ax.set_title(\"Treatment: \" + str(treatment) + \"   Analyte: \" + str(analyte)+\"  Correlation: \" + str(corr)+\"  Size: \" + str(X.size))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# for analyte in unique_analytes:\n",
    "#     # plot_1d(\"Pembrolizumab\",\"MCP-4\")\n",
    "#     plot_1d(\"GEN1053\",analyte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Method of computation gotten and adapted from \n",
    "Taketa, K., & Pogell, B. M. (1965). Allosteric inhibition of rat liver fructose 1, 6-diphosphatase by adenosine 5'-monophosphate. Journal of Biological Chemistry, 240(2), 651-662.\n",
    "Altszyler, E., Ventura, A. C., Colman-Lerner, A., & Chernomoretz, A. (2017). Ultrasensitivity in signaling cascades revisited: Linking local and global ultrasensitivity estimations. PloS one, 12(6), e0180083. https://doi.org/10.1371/journal.pone.0180083\n",
    "Inspiration of designing this method is also from Rob Mulla on https://www.youtube.com/watch?v=QpzMWQvxXWk\n",
    "\"\"\"\n",
    "# Method to see if we can compute the Hill coefficient\n",
    "def Hill_coef_computable(data,X,y):\n",
    "    y_max = data[y].max()\n",
    "    y_min = data[y].min()\n",
    "    y_range = y_max - y_min\n",
    "    X_max = data.loc[(data[y]>0.9 * y_range + y_min) & (data[y]< y_max), X]\n",
    "    X_min = data.loc[(data[y]<0.1 * y_range + y_min) & (data[y]> y_min), X]\n",
    "    if X_max.size == 0:\n",
    "        return False\n",
    "    if X_min.size == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Method of computation gotten and adapted from \n",
    "Taketa, K., & Pogell, B. M. (1965). Allosteric inhibition of rat liver fructose 1, 6-diphosphatase by adenosine 5'-monophosphate. Journal of Biological Chemistry, 240(2), 651-662.\n",
    "Altszyler, E., Ventura, A. C., Colman-Lerner, A., & Chernomoretz, A. (2017). Ultrasensitivity in signaling cascades revisited: Linking local and global ultrasensitivity estimations. PloS one, 12(6), e0180083. https://doi.org/10.1371/journal.pone.0180083\n",
    "\"\"\"\n",
    "# Method to compute the hill coefficient\n",
    "def Hill_coef(data,X,y):\n",
    "    y_max = data[y].max()\n",
    "    y_min = data[y].min()\n",
    "    y_range = y_max - y_min\n",
    "    X_90 = data.loc[data[y]>0.9 * y_range + y_min, X].min()\n",
    "    X_10 = data.loc[data[y]<0.1 * y_range + y_min, X].max()\n",
    "    quotient = X_90/X_10\n",
    "    coef = math.log10(81)/math.log10(quotient)\n",
    "    return coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "This is based on Hill equation defined in\n",
    "Neubig, R. R., Spedding, M., Kenakin, T., & Christopoulos, A. (2003). International Union of Pharmacology Committee on Receptor Nomenclature and Drug Classification. XXXVIII. Update on terms and symbols in quantitative pharmacology. Pharmacological reviews, 55(4), 597-606.\n",
    "and logistic function\n",
    "https://en.wikipedia.org/wiki/Logistic_function\n",
    "also helped by\n",
    "Han, J., & Moraga, C. (1995, June). The influence of the sigmoid function parameters on the speed of backpropagation learning. In International workshop on artificial neural networks (pp. 195-201). Berlin, Heidelberg: Springer Berlin Heidelberg.\n",
    "https://en.wikipedia.org/wiki/Sigmoid_function\n",
    "\"\"\"\n",
    "def inverse_logistic(data,k,middle_y=\"NA\",c=0.001):\n",
    "    y_max = data.max()\n",
    "    y_min = data.min()\n",
    "    y_range = y_max - y_min\n",
    "    y_min_new = y_min - c * y_range\n",
    "    y_new = data - y_min_new\n",
    "    if (middle_y == \"NA\") | (2 * middle_y <= y_new.max()):\n",
    "        y_max_new = y_max - y_min_new + c * y_range\n",
    "    else:\n",
    "        y_max_new = 2 * middle_y + c * y_range\n",
    "    inverse_list = y_max_new/y_new - 1\n",
    "    inverse_list_1 = []\n",
    "    for inverse in inverse_list:\n",
    "        # if type(inverse) is float:\n",
    "        # print(inverse)\n",
    "        inverse_list_1.append(-math.log(inverse)/k)\n",
    "    # return pd.DataFrame(inverse_list_1,columns=[\"y_after\"])\n",
    "    return inverse_list_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"This is based on the method inverse_logistic and might be based on some references it uses\"\"\"\n",
    "\n",
    "# Building a model based on the inverse logistic preprocessing\n",
    "# This part is mostly testing whether it gives the original data back after performing inverse-logistic and logistic\n",
    "data_focused_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==\"Pembrolizumab\") &\n",
    "                        (mlr_data[\"treatment_2\"]==\"GEN1053\") &\n",
    "                        (mlr_data[\"analyte\"]==\"MCP-4\")\n",
    "                        ]\n",
    "data_focused_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==\"Pembrolizumab\") &\n",
    "                        (mlr_data[\"treatment_1\"]==\"GEN1053\") &\n",
    "                        (mlr_data[\"analyte\"]==\"MCP-4\")\n",
    "                        ]\n",
    "data_focused_2 = data_focused_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "data_focused = pd.concat([data_focused_1,data_focused_2])\n",
    "# print(inverse_logistic(data_focused,1))\n",
    "X = data_focused[[\"concentration_1\",\"concentration_2\"]]\n",
    "y = data_focused[\"analyte_value\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "y_max = y_train.max()\n",
    "y_min = y_train.min()\n",
    "y_range = y_max - y_min\n",
    "# zero_y = abs(y_train-0.5 * y_range - y_min).min()\n",
    "r_2_score_train_max=0\n",
    "middle_y_best = 0\n",
    "k_best = 1\n",
    "r_2_list = []\n",
    "middle_y_list = []\n",
    "k_list = []\n",
    "for middle_y in y_train:\n",
    "    model = LinearRegression()\n",
    "    c = 0.001\n",
    "    for k in np.arange(start=0.01,stop=100,step=1):\n",
    "        y_train_new = inverse_logistic(y_train,k,middle_y=middle_y, c=c)\n",
    "        y_max = y_train.max()\n",
    "        y_min = y_train.min()\n",
    "        y_range = y_max - y_min\n",
    "        y_min_new = y_min - c * y_range\n",
    "        y_new = y_train - y_min_new\n",
    "        if (middle_y == \"NA\") | (2 * middle_y <= y_new.max()):\n",
    "            y_max_new = y_max - y_min_new + c * y_range\n",
    "        else:\n",
    "            y_max_new = 2 * middle_y + c * y_range\n",
    "            model.fit(X_train,y_train_new)\n",
    "            predictions = model.predict(X_train)\n",
    "            predictions_new = []\n",
    "            # for x in predictions:\n",
    "            for x in y_train_new:\n",
    "                output = y_max_new/(1+math.e ** (-k * x)) + y_min_new\n",
    "                predictions_new.append(output)\n",
    "            predictions_new = pd.DataFrame(predictions_new)\n",
    "            # print(r2_score(y_train,predictions_new))\n",
    "            if r_2_score_train_max < r2_score(y_train,predictions_new):\n",
    "                r_2_score_train_max = r2_score(y_train,predictions_new)\n",
    "                middle_y_best = middle_y\n",
    "                k_best = k\n",
    "            r_2_list.append(r2_score(y_train,predictions_new))\n",
    "            middle_y_list.append(middle_y)\n",
    "            k_list.append(k)\n",
    "print(r_2_score_train_max)\n",
    "print(middle_y_best,k_best)\n",
    "overall_list = {}\n",
    "overall_list[\"middle_y\"]=middle_y_list\n",
    "overall_list[\"k\"]=k_list\n",
    "overall_list[\"r_2\"]=r_2_list\n",
    "overall_list = pd.DataFrame(overall_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "This is based on the method inverse_logistic and might be based on some references it uses\n",
    "Helped by \n",
    "https://www.youtube.com/watch?v=3CCkeFShB3U\n",
    "https://www.youtube.com/watch?v=kE_I-5rxtEA&t=164s\n",
    "\"\"\"\n",
    "\n",
    "# Building a model based on the inverse logistic preprocessing\n",
    "\n",
    "# print(inverse_logistic(data_focused,1))\n",
    "X = data_focused[[\"concentration_1\",\"concentration_2\"]]\n",
    "X[\"interaction\"] = X[\"concentration_1\"].mul(X[\"concentration_2\"])\n",
    "y = data_focused[\"analyte_value\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "y_max = y_train.max()\n",
    "y_min = y_train.min()\n",
    "y_range = y_max - y_min\n",
    "r_2_score_train_max=0\n",
    "middle_y_best = 0\n",
    "k_best = 1\n",
    "r_2_list = []\n",
    "middle_y_list = []\n",
    "k_list = []\n",
    "for middle_y in y_train:\n",
    "    model = LinearRegression()\n",
    "    c = 0.001\n",
    "    for k in np.arange(start=0.01,stop=100,step=1):\n",
    "        y_train_new = inverse_logistic(y_train,k,middle_y=middle_y, c=c)\n",
    "        y_max = y_train.max()\n",
    "        y_min = y_train.min()\n",
    "        y_range = y_max - y_min\n",
    "        y_min_new = y_min - c * y_range\n",
    "        y_new = y_train - y_min_new\n",
    "        if (middle_y == \"NA\") | (2 * middle_y <= y_new.max()):\n",
    "            y_max_new = y_max - y_min_new + c * y_range\n",
    "        else:\n",
    "            y_max_new = 2 * middle_y + c * y_range\n",
    "            model.fit(X_train,y_train_new)\n",
    "            predictions = model.predict(X_test)\n",
    "            predictions_new = []\n",
    "            # for x in predictions:\n",
    "            for x in predictions:\n",
    "                output = y_max_new/(1+math.e ** (-k * x)) + y_min_new\n",
    "                predictions_new.append(output)\n",
    "            predictions_new = pd.DataFrame(predictions_new)\n",
    "            # print(r2_score(y_train,predictions_new))\n",
    "            if r_2_score_train_max < r2_score(y_test,predictions_new):\n",
    "                r_2_score_train_max = r2_score(y_test,predictions_new)\n",
    "                middle_y_best = middle_y\n",
    "                k_best = k\n",
    "            r_2_list.append(r2_score(y_test,predictions_new))\n",
    "            middle_y_list.append(middle_y)\n",
    "            k_list.append(k)\n",
    "print(r_2_score_train_max)\n",
    "print(middle_y_best,k_best)\n",
    "overall_list_test = {}\n",
    "overall_list_test[\"middle_y\"]=middle_y_list\n",
    "overall_list_test[\"k\"]=k_list\n",
    "overall_list_test[\"r_2\"]=r_2_list\n",
    "overall_list_test = pd.DataFrame(overall_list_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "This is based on the method inverse_logistic and might be based on some references it uses\n",
    "Helped by \n",
    "https://www.youtube.com/watch?v=3CCkeFShB3U\n",
    "https://www.youtube.com/watch?v=kE_I-5rxtEA&t=164s\n",
    "\"\"\"\n",
    "\n",
    "# Building a model based on the inverse logistic preprocessing\n",
    "\n",
    "# print(inverse_logistic(data_focused,1))\n",
    "\n",
    "def logistic_model(treatment_1,treatment_2,analyte):\n",
    "    data_focused_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_2\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_focused_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_1\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_focused_2 = data_focused_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "    data_focused = pd.concat([data_focused_1,data_focused_2])\n",
    "    X = data_focused[[\"concentration_1\",\"concentration_2\"]]\n",
    "    X[\"interaction\"] = X[\"concentration_1\"].mul(X[\"concentration_2\"])\n",
    "    y = data_focused[\"analyte_value\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "    y_max = y_train.max()\n",
    "    y_min = y_train.min()\n",
    "    y_range = y_max - y_min\n",
    "    r_2_score_train_max=0\n",
    "    middle_y_best = 0\n",
    "    k_best = 1\n",
    "    r_2_list = []\n",
    "    middle_y_list = []\n",
    "    k_list = []\n",
    "    for middle_y in y_train:\n",
    "        model = LinearRegression()\n",
    "        c = 0.001\n",
    "        for k in np.arange(start=0.01,stop=100,step=1):\n",
    "            y_train_new = inverse_logistic(y_train,k,middle_y=middle_y, c=c)\n",
    "            y_max = y_train.max()\n",
    "            y_min = y_train.min()\n",
    "            y_range = y_max - y_min\n",
    "            y_min_new = y_min - c * y_range\n",
    "            y_new = y_train - y_min_new\n",
    "            if (middle_y == \"NA\") | (2 * middle_y <= y_new.max()):\n",
    "                y_max_new = y_max - y_min_new + c * y_range\n",
    "            else:\n",
    "                y_max_new = 2 * middle_y + c * y_range\n",
    "                model.fit(X_train,y_train_new)\n",
    "                predictions = model.predict(X_test)\n",
    "                predictions_new = []\n",
    "                # for x in predictions:\n",
    "                for x in predictions:\n",
    "                    output = y_max_new/(1+math.e ** (-k * x)) + y_min_new\n",
    "                    predictions_new.append(output)\n",
    "                predictions_new = pd.DataFrame(predictions_new)\n",
    "                # print(r2_score(y_train,predictions_new))\n",
    "                if r_2_score_train_max < r2_score(y_test,predictions_new):\n",
    "                    r_2_score_train_max = r2_score(y_test,predictions_new)\n",
    "                    middle_y_best = middle_y\n",
    "                    k_best = k\n",
    "                r_2_list.append(r2_score(y_test,predictions_new))\n",
    "                middle_y_list.append(middle_y)\n",
    "                k_list.append(k)\n",
    "    return r_2_score_train_max,middle_y_best,k_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "The design of this method is inspired by Rob Mulla on https://www.youtube.com/watch?v=QpzMWQvxXWk\n",
    "\"\"\"\n",
    "def plotable(treatment_1, treatment_2, analyte):\n",
    "    data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_2\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_1\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "    data = pd.concat([data_1,data_2])\n",
    "    # data_2 = data.loc[data[\"concentration_1\"]==0]\n",
    "    # data_1 = data.loc[data[\"concentration_2\"]==0]\n",
    "    # Check if the data has less than 30 samples\n",
    "    if data[\"treatment_1\"].size<30:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# treatments = [\"GEN1056\",\"GEN1053\",\"Pembrolizumab\"]\n",
    "# treatment_1_list = []\n",
    "# treatment_2_list = []\n",
    "# analyte_list = []\n",
    "# r_2_score_train_max_list=[]\n",
    "# middle_y_best_list = []\n",
    "# k_best_list = []\n",
    "\n",
    "# treatment_1 = \"GEN1056\"\n",
    "# for treatment_2 in [\"GEN1053\",\"Pembrolizumab\"]:\n",
    "#     if treatment_2 != treatment_1:\n",
    "#         for analyte in unique_analytes:\n",
    "#             if plotable(treatment_1,treatment_2,analyte):\n",
    "#                 r_2_score_train_max,middle_y_best,k_best = logistic_model(treatment_1,treatment_2,analyte)\n",
    "#                 r_2_score_train_max_list.append(r_2_score_train_max)\n",
    "#                 middle_y_best_list.append(middle_y_best)\n",
    "#                 k_best_list.append(k_best)\n",
    "#                 treatment_1_list.append(treatment_1)\n",
    "#                 treatment_2_list.append(treatment_2)\n",
    "#                 analyte_list.append(analyte)\n",
    "# treatment_1 = \"GEN1053\"\n",
    "# for treatment_2 in [\"Pembrolizumab\"]:\n",
    "#     if treatment_2 != treatment_1:\n",
    "#         for analyte in unique_analytes:\n",
    "#             if plotable(treatment_1,treatment_2,analyte):\n",
    "#                 r_2_score_train_max,middle_y_best,k_best = logistic_model(treatment_1,treatment_2,analyte)\n",
    "#                 r_2_score_train_max_list.append(r_2_score_train_max)\n",
    "#                 middle_y_best_list.append(middle_y_best)\n",
    "#                 k_best_list.append(k_best)\n",
    "#                 treatment_1_list.append(treatment_1)\n",
    "#                 treatment_2_list.append(treatment_2)\n",
    "#                 analyte_list.append(analyte)\n",
    "\n",
    "# modeling_result = {}\n",
    "# modeling_result[\"treatment_1\"]=treatment_1_list\n",
    "# modeling_result[\"treatment_2\"]=treatment_2_list\n",
    "# modeling_result[\"analyte\"]=analyte_list\n",
    "# modeling_result[\"r_2_score\"]=r_2_score_train_max_list\n",
    "# modeling_result = pd.DataFrame(modeling_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# r_2_scores=[]\n",
    "#     for k in np.arange(start=0.01,stop=1,step=0.1):\n",
    "#         y_train_new = inverse_logistic(y_train,k)\n",
    "#         # print(y_train_new.head())\n",
    "#         model.fit(X_train,y_train_new)\n",
    "#         predictions = model.predict(X_test)\n",
    "#         predictions_new = []\n",
    "#         for x in predictions:\n",
    "#             output = math.e ** (-k * x)\n",
    "#             output = y_max_new/(1+output)\n",
    "#             predictions_new.append(output)\n",
    "#         predictions_new = pd.DataFrame(predictions_new)\n",
    "#         r_2_scores.append(r2_score(y_test,predictions_new))\n",
    "#     r_2_scores = pd.DataFrame(r_2_scores)\n",
    "#     print(r_2_scores.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# data = mlr_data.loc[\n",
    "#         (mlr_data[\"treatment_1\"] == \"GEN1056\") & \n",
    "#         (mlr_data[\"treatment_2\"] == \"GEN1053\") & \n",
    "#         (mlr_data[\"analyte\"] == \"IL-10\"), \n",
    "#         [\"concentration_1\", \"concentration_2\", \"analyte_value\"]\n",
    "#     ]\n",
    "# data_1 = data.loc[data[\"concentration_2\"]==0]\n",
    "# # print(data_1)\n",
    "# print(Hill_coef(data_1,\"concentration_1\",\"analyte_value\"))\n",
    "# Hill_coef_computable(data_1,\"concentration_1\",\"analyte_value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Part of code in this method is adapted from https://matplotlib.org/stable/plot_types/3D/scatter3d_simple.html#sphx-glr-plot-types-3d-scatter3d-simple-py\n",
    "and helped by other examples from the official website of matplotlib: https://matplotlib.org/stable/\n",
    "\"\"\"\n",
    "def plot(treatment_1, treatment_2, analyte):\n",
    "    data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_2\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_1\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "    data = pd.concat([data_1,data_2])\n",
    "    \n",
    "    # Check if the data is empty\n",
    "    if not plotable(treatment_1, treatment_2, analyte):\n",
    "        print(f\"Skipping {analyte} due to insufficient data.\")\n",
    "        return \n",
    "    \n",
    "    xs = data[\"concentration_1\"].values\n",
    "    ys = data[\"concentration_2\"].values\n",
    "    zs = data[\"analyte_value\"].values\n",
    "    X = data[[\"concentration_1\", \"concentration_2\"]]\n",
    "    y = zs\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(data[[\"concentration_1\", \"concentration_2\"]], zs)\n",
    "\n",
    "    # Create a grid for plotting the regression plane\n",
    "    x_pred = np.linspace(xs.min(), xs.max(), 30)\n",
    "    y_pred = np.linspace(ys.min(), ys.max(), 30)\n",
    "    x_pred, y_pred = np.meshgrid(x_pred, y_pred)\n",
    "    z_pred = model.predict(np.c_[x_pred.ravel(), y_pred.ravel()]).reshape(x_pred.shape)\n",
    "    \n",
    "    # Compute the mean of cross validation results of r square\n",
    "    r_square = -cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xs, ys, zs, color='blue', label='Data points')\n",
    "    ax.plot_surface(x_pred, y_pred, z_pred, color='red', alpha=0.5, rstride=100, cstride=100)\n",
    "    \n",
    "    # Adding contour plot\n",
    "    contour = ax.contourf(x_pred, y_pred, z_pred, zdir='z', offset=zs.min(), cmap='viridis', alpha=0.5)\n",
    "    fig.colorbar(contour, ax=ax, shrink=0.5, aspect=5)\n",
    "    \n",
    "    ax.set_xlabel(treatment_1 + \" concentration\")\n",
    "    ax.set_ylabel(treatment_2 + \" concentration\")\n",
    "    ax.set_zlabel(analyte + \" value\")\n",
    "    ax.set_title(f\"3D Surface Plot with Regression Plane and Contours for {analyte}\" \" r square: \" + str(r_square))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Helped by \n",
    "https://www.youtube.com/watch?v=3CCkeFShB3U\n",
    "https://www.youtube.com/watch?v=kE_I-5rxtEA&t=164s\n",
    "\"\"\"\n",
    "\n",
    "# Computes the r^2 of model fit on specified treatments and analyte and dimension\n",
    "\n",
    "def r_square(treatment_1, treatment_2, analyte, dimension=1):\n",
    "    data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_2\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_1\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "    data = pd.concat([data_1,data_2])\n",
    "    \n",
    "    # Check if the data is empty\n",
    "    if not plotable(treatment_1, treatment_2, analyte):\n",
    "        return \n",
    "    \n",
    "    X = data[[\"concentration_1\", \"concentration_2\"]]\n",
    "    y = data[\"analyte_value\"].values\n",
    "    if dimension == \"interactive\":\n",
    "        X[\"interaction\"] = X[\"concentration_1\"].mul(X[\"concentration_2\"])\n",
    "    else:\n",
    "        polynomial = PolynomialFeatures(dimension)\n",
    "        X = polynomial.fit_transform(X)\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Compute the mean of cross validation results of r square\n",
    "    # r_square = -cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()\n",
    "    r_square = cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()\n",
    "    return r_square\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# cross_val_mae(\"GEN1056\",\"GEN1053\",\"IL-10\",\"interactive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Part of code in this mehtod is adapted from https://matplotlib.org/stable/plot_types/3D/scatter3d_simple.html#sphx-glr-plot-types-3d-scatter3d-simple-py\n",
    "and helped by other examples from the official website of matplotlib: https://matplotlib.org/stable/\n",
    "Helped by \n",
    "https://www.youtube.com/watch?v=3CCkeFShB3U\n",
    "https://www.youtube.com/watch?v=kE_I-5rxtEA&t=164s\n",
    "\"\"\"\n",
    "def poly_plot(treatment_1, treatment_2, analyte, dimension):\n",
    "    data_1 = mlr_data.loc[ (mlr_data[\"treatment_1\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_2\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = mlr_data.loc[ (mlr_data[\"treatment_2\"]==treatment_1) &\n",
    "                            (mlr_data[\"treatment_1\"]==treatment_2) &\n",
    "                            (mlr_data[\"analyte\"]==analyte)\n",
    "                            ]\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\":\"treatment_1\",\"treatment_1\":\"treatment_2\",\"concentration_1\":\"concentration_2\",\"concentration_2\":\"concentration_1\"})\n",
    "    data = pd.concat([data_1,data_2])\n",
    "    \n",
    "    # Check if the data is empty\n",
    "    if not plotable(treatment_1, treatment_2, analyte):\n",
    "        print(f\"Skipping {analyte} due to insufficient data.\")\n",
    "        return \n",
    "    \n",
    "    xs = data[\"concentration_1\"].values\n",
    "    ys = data[\"concentration_2\"].values\n",
    "    zs = data[\"analyte_value\"].values\n",
    "    X = data[[\"concentration_1\", \"concentration_2\"]]\n",
    "    if dimension == \"interactive\":\n",
    "        X[\"interaction\"] = X[\"concentration_1\"].mul(X[\"concentration_2\"])\n",
    "    else:\n",
    "        polynomial = PolynomialFeatures(dimension)\n",
    "        X = polynomial.fit_transform(X)\n",
    "    y = zs\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(xs,ys, zs)\n",
    "\n",
    "    # Create a grid for plotting the regression plane\n",
    "    x_pred = np.linspace(xs.min(), xs.max(), 30)\n",
    "    y_pred = np.linspace(ys.min(), ys.max(), 30)\n",
    "    x_pred, y_pred = np.meshgrid(x_pred, y_pred)\n",
    "    z_pred = model.predict(np.c_[x_pred.ravel(), y_pred.ravel()]).reshape(x_pred.shape)\n",
    "    \n",
    "    # Compute the mean of cross validation results of r square\n",
    "    # r_square = -cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()\n",
    "    r_square = cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xs, ys, zs, color='blue', label='Data points')\n",
    "    ax.plot_surface(x_pred, y_pred, z_pred, color='red', alpha=0.5, rstride=100, cstride=100)\n",
    "    \n",
    "    # Adding contour plot\n",
    "    contour = ax.contourf(x_pred, y_pred, z_pred, zdir='z', offset=zs.min(), cmap='viridis', alpha=0.5)\n",
    "    fig.colorbar(contour, ax=ax, shrink=0.5, aspect=5)\n",
    "    \n",
    "    ax.set_xlabel(treatment_1 + \" concentration\")\n",
    "    ax.set_ylabel(treatment_2 + \" concentration\")\n",
    "    ax.set_zlabel(analyte + \" value\")\n",
    "    ax.set_title(f\"3D Surface Plot with Regression Plane and Contours for {analyte}\" \" r square: \" + str(r_square))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "GEN1056_GEN1053_error_table = {}\n",
    "analytes = []\n",
    "errors = [[],[],[],[]]\n",
    "for dimension in range (1,4):\n",
    "    for analyte in unique_analytes:\n",
    "        if plotable(\"GEN1056\", \"GEN1053\", analyte):\n",
    "            # plot(\"GEN1056\", \"GEN1053\", analyte)\n",
    "            if analyte not in analytes:\n",
    "                analytes.append(analyte)\n",
    "            errors[dimension-1].append(float(r_square(\"GEN1056\", \"GEN1053\", analyte, dimension=dimension)))\n",
    "    GEN1056_GEN1053_error_table[\"dimension \"+str(dimension)+\" r square\"] = errors[dimension-1]\n",
    "for analyte in unique_analytes:\n",
    "    if plotable(\"GEN1056\", \"GEN1053\", analyte):\n",
    "        # plot(\"GEN1053\", \"Pembrolizumab\", analyte)\n",
    "        errors[3].append(float(r_square(\"GEN1056\", \"GEN1053\", analyte, dimension=\"interactive\")))\n",
    "GEN1056_GEN1053_error_table[\"interaction r square\"]=errors[3]\n",
    "GEN1056_GEN1053_error_table[\"analyte\"]=analytes\n",
    "GEN1056_GEN1053_error_table = pd.DataFrame(GEN1056_GEN1053_error_table)\n",
    "GEN1056_GEN1053_error_table[\"maximum\"]=GEN1056_GEN1053_error_table[[\"dimension 1 r square\",\"dimension 2 r square\", \"dimension 3 r square\", \"interaction r square\"]].max(axis=1)\n",
    "GEN1056_GEN1053_error_table[\"maximum_id\"]=GEN1056_GEN1053_error_table[[\"dimension 1 r square\",\"dimension 2 r square\", \"dimension 3 r square\", \"interaction r square\"]].idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "GEN1053_Pembrolizumab_error_table = {}\n",
    "analytes = []\n",
    "errors = [[],[],[],[]]\n",
    "for dimension in range (1,4):\n",
    "    for analyte in unique_analytes:\n",
    "        if plotable(\"GEN1053\", \"Pembrolizumab\", analyte):\n",
    "            # plot(\"GEN1053\", \"Pembrolizumab\", analyte)\n",
    "            if analyte not in analytes:\n",
    "                analytes.append(analyte)\n",
    "            errors[dimension-1].append(float(r_square(\"GEN1053\", \"Pembrolizumab\", analyte, dimension=dimension)))\n",
    "    GEN1053_Pembrolizumab_error_table[\"dimension \"+str(dimension)+\" r square\"] = errors[dimension-1]\n",
    "for analyte in unique_analytes:\n",
    "    if plotable(\"GEN1053\", \"Pembrolizumab\", analyte):\n",
    "        # plot(\"GEN1053\", \"Pembrolizumab\", analyte)\n",
    "        errors[3].append(float(r_square(\"GEN1053\", \"Pembrolizumab\", analyte, dimension=\"interactive\")))\n",
    "GEN1053_Pembrolizumab_error_table[\"interaction r square\"]=errors[3]\n",
    "GEN1053_Pembrolizumab_error_table[\"analyte\"]=analytes\n",
    "GEN1053_Pembrolizumab_error_table = pd.DataFrame(GEN1053_Pembrolizumab_error_table)\n",
    "GEN1053_Pembrolizumab_error_table[\"maximum\"]=GEN1053_Pembrolizumab_error_table[[\"dimension 1 r square\",\"dimension 2 r square\", \"dimension 3 r square\", \"interaction r square\"]].max(axis=1)\n",
    "GEN1053_Pembrolizumab_error_table[\"maximum_id\"]=GEN1053_Pembrolizumab_error_table[[\"dimension 1 r square\",\"dimension 2 r square\", \"dimension 3 r square\", \"interaction r square\"]].idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "GEN1056_GEN1053_error_table = GEN1056_GEN1053_error_table.sort_values(by=['maximum'],ascending=False)\n",
    "GEN1053_Pembrolizumab_error_table = GEN1053_Pembrolizumab_error_table.sort_values(by=['maximum'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print(GEN1056_GEN1053_error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print(GEN1053_Pembrolizumab_error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "treatment_1 = \"Pembrolizumab\"\n",
    "treatment_2 = \"GEN1053\"\n",
    "\n",
    "for analyte in [\"IL-1a\", \"Eotaxin-3\", \"IL-7\", \"CD30/TNFRSF8\", \"IP-10\", \"IL-5\"]:\n",
    "    r_square_dim1 = r_square(treatment_1, treatment_2, analyte, dimension=1)\n",
    "    r_square_interactive = r_square(treatment_1, treatment_2, analyte, dimension=\"interactive\")\n",
    "    logistic_result = logistic_model(treatment_1, treatment_2, analyte)\n",
    "    \n",
    "    # Fetch data\n",
    "    data_1 = mlr_data.loc[(mlr_data[\"treatment_1\"] == treatment_1) &\n",
    "                          (mlr_data[\"treatment_2\"] == treatment_2) &\n",
    "                          (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    data_2 = mlr_data.loc[(mlr_data[\"treatment_2\"] == treatment_1) &\n",
    "                          (mlr_data[\"treatment_1\"] == treatment_2) &\n",
    "                          (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    # Rename columns for consistency\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\": \"treatment_1\", \n",
    "                                    \"treatment_1\": \"treatment_2\", \n",
    "                                    \"concentration_1\": \"concentration_2\", \n",
    "                                    \"concentration_2\": \"concentration_1\"})\n",
    "    \n",
    "    # Combine the datasets\n",
    "    data = pd.concat([data_1, data_2])\n",
    "\n",
    "    # Print relevant output in a clean way\n",
    "    print(f\"Analyte: {analyte}\")\n",
    "    print(f\"R^2 (dimension=1): {r_square_dim1:.4f}\")\n",
    "    print(f\"R^2 (interactive): {r_square_interactive:.4f}\")\n",
    "    print(f\"Logistic Model Result: {logistic_result}\")\n",
    "    print(f\"Data Size: {data['analyte_value'].size}\")\n",
    "    print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Define the new cross-validation logistic model (logistic_model_cv)\n",
    "def logistic_model_cv(treatment_1, treatment_2, analyte, n_splits=5):\n",
    "    data_focused_1 = mlr_data.loc[(mlr_data[\"treatment_1\"] == treatment_1) &\n",
    "                                  (mlr_data[\"treatment_2\"] == treatment_2) &\n",
    "                                  (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    data_focused_2 = mlr_data.loc[(mlr_data[\"treatment_2\"] == treatment_1) &\n",
    "                                  (mlr_data[\"treatment_1\"] == treatment_2) &\n",
    "                                  (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    data_focused_2 = data_focused_2.rename(columns={\"treatment_2\": \"treatment_1\",\n",
    "                                                    \"treatment_1\": \"treatment_2\",\n",
    "                                                    \"concentration_1\": \"concentration_2\",\n",
    "                                                    \"concentration_2\": \"concentration_1\"})\n",
    "    \n",
    "    data_focused = pd.concat([data_focused_1, data_focused_2])\n",
    "    X = data_focused[[\"concentration_1\", \"concentration_2\"]]\n",
    "    X[\"interaction\"] = X[\"concentration_1\"].mul(X[\"concentration_2\"])\n",
    "    y = data_focused[\"analyte_value\"]\n",
    "\n",
    "    # Initialize KFold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    r_2_list = []\n",
    "    middle_y_best = None\n",
    "    k_best = None\n",
    "    r_2_score_cv_max = -np.inf\n",
    "    \n",
    "    # Iterate over each fold\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Define the logistic regression process for this fold\n",
    "        for middle_y in y_train:\n",
    "            model = LinearRegression()\n",
    "            c = 0.001\n",
    "            for k in np.arange(start=0.01, stop=100, step=1):\n",
    "                y_train_new = inverse_logistic(y_train, k, middle_y=middle_y, c=c)\n",
    "\n",
    "                # Train model\n",
    "                model.fit(X_train, y_train_new)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                predictions = model.predict(X_val)\n",
    "\n",
    "                # Convert predictions back using logistic function\n",
    "                y_min_new = y_train.min() - c * (y_train.max() - y_train.min())\n",
    "                if middle_y is None or (2 * middle_y <= y_train.max()):\n",
    "                    y_max_new = y_train.max() - y_min_new + c * (y_train.max() - y_train.min())\n",
    "                else:\n",
    "                    y_max_new = 2 * middle_y + c * (y_train.max() - y_train.min())\n",
    "                \n",
    "                predictions_new = [y_max_new / (1 + math.exp(-k * pred)) + y_min_new for pred in predictions]\n",
    "                \n",
    "                # Calculate R² score for this fold\n",
    "                r2 = r2_score(y_val, predictions_new)\n",
    "                r_2_list.append(r2)\n",
    "\n",
    "                # Track the best middle_y and k\n",
    "                if r2 > r_2_score_cv_max:\n",
    "                    r_2_score_cv_max = r2\n",
    "                    middle_y_best = middle_y\n",
    "                    k_best = k\n",
    "\n",
    "    # Average R² score across all folds\n",
    "    r2_average = np.mean(r_2_list)\n",
    "    \n",
    "    return r2_average, middle_y_best, k_best\n",
    "\n",
    "# Loop through the analytes and calculate R² scores and logistic model results\n",
    "treatment_1 = \"Pembrolizumab\"\n",
    "treatment_2 = \"GEN1053\"\n",
    "\n",
    "for analyte in [\"IL-1a\", \"Eotaxin-3\", \"IL-7\", \"CD30/TNFRSF8\", \"IP-10\", \"IL-5\"]:\n",
    "    r_square_dim1 = r_square(treatment_1, treatment_2, analyte, dimension=1)\n",
    "    r_square_interactive = r_square(treatment_1, treatment_2, analyte, dimension=\"interactive\")\n",
    "    \n",
    "    # Use the cross-validated logistic model\n",
    "    r2_score_cv, best_middle_y, best_k = logistic_model_cv(treatment_1, treatment_2, analyte)\n",
    "    \n",
    "    # Fetch data\n",
    "    data_1 = mlr_data.loc[(mlr_data[\"treatment_1\"] == treatment_1) &\n",
    "                          (mlr_data[\"treatment_2\"] == treatment_2) &\n",
    "                          (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    data_2 = mlr_data.loc[(mlr_data[\"treatment_2\"] == treatment_1) &\n",
    "                          (mlr_data[\"treatment_1\"] == treatment_2) &\n",
    "                          (mlr_data[\"analyte\"] == analyte)]\n",
    "    \n",
    "    # Rename columns for consistency\n",
    "    data_2 = data_2.rename(columns={\"treatment_2\": \"treatment_1\", \n",
    "                                    \"treatment_1\": \"treatment_2\", \n",
    "                                    \"concentration_1\": \"concentration_2\", \n",
    "                                    \"concentration_2\": \"concentration_1\"})\n",
    "    \n",
    "    # Combine the datasets\n",
    "    data = pd.concat([data_1, data_2])\n",
    "\n",
    "    # Print relevant output in a clean way\n",
    "    print(f\"Analyte: {analyte}\")\n",
    "    print(f\"R^2 (dimension=1): {r_square_dim1:.4f}\")\n",
    "    print(f\"R^2 (interactive): {r_square_interactive:.4f}\")\n",
    "    print(f\"Cross-validated Logistic Model Result (R²): {r2_score_cv:.4f}, Best middle_y: {best_middle_y}, Best k: {best_k}\")\n",
    "    print(f\"Data Size: {data['analyte_value'].size}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
